{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/CNN/YOLO_webcam.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/YOLO_webcam.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOxk_EJvWg40"
   },
   "source": [
    "This is a demo from [Gluon](https://cv.gluon.ai/build/examples_detection/demo_webcam.html)\n",
    "\n",
    "You need to install gluon and opencv. [Installation guide](https://cv.gluon.ai/install.html)\n",
    "```shell\n",
    "# for mxnet\n",
    "pip install --upgrade mxnet\n",
    "# for pytorch\n",
    "pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "pip install --upgrade gluoncv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "396xUGMtWif2"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade mxnet\n",
    "#!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#!pip install --upgrade gluoncv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YYHT7RcWg41"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import gluoncv as gcv\n",
    "from gluoncv.utils import try_import_cv2\n",
    "cv2 = try_import_cv2()\n",
    "import mxnet as mx\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iurw90vqWg41"
   },
   "source": [
    "We can use ssd_512_mobilenet1.0_voc or any other [model](https://cv.gluon.ai/model_zoo/detection.html), for example `ssd_512_resnet50_v1_voc` or `yolo3_darknet53_voc` or `faster_rcnn_fpn_syncbn_resnest269_coco` or `faster_rcnn_fpn_resnet50_v1b_coco`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yl9mrPX4Wg42",
    "outputId": "d63a1a5c-e17c-48e0-a0d9-8532d19e2e9a"
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "net = gcv.model_zoo.get_model('ssd_512_mobilenet1.0_voc', pretrained=True)\n",
    "# Compile the model for faster speed\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "CO1JQobEXqai",
    "outputId": "a5c4fe4d-2e8b-4ec5-f7ac-64d893156500",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Detect one image\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "def read_image(image_path, target_size=None):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path,\n",
    "                target_size=target_size)\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "url = 'https://akm-img-a-in.tosshub.com/indiatoday/images/story/201812/dogs_and_cats.jpeg?TAxD19DTCFE7WiSYLUdTu446cfW4AbuW&size=770:433'\n",
    "image_path = tf.keras.utils.get_file(\"dog-cat2.jpg\", url)\n",
    "image = read_image(image_path)\n",
    "plt.imshow(image)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "id": "RNooZ7QxYu_A",
    "outputId": "714b99b9-5460-4fec-b9ae-4b3338452541"
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "frame = mx.nd.array(image) # torch.from_numpy(image).long()\n",
    "rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)\n",
    "# Run frame through network\n",
    "class_IDs, scores, bounding_boxes = net(rgb_nd)\n",
    "\n",
    "# Display the result\n",
    "img = gcv.utils.viz.cv_plot_bbox(frame, bounding_boxes[0], scores[0], class_IDs[0], class_names=net.classes)\n",
    "#from google.colab.patches import cv2_imshow\n",
    "#gcv.utils.viz.cv_plot_image(img)\n",
    "#cv2_imshow(img)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3LMm8VXiZal"
   },
   "source": [
    "## Web cam Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTiUAdTQWg42"
   },
   "outputs": [],
   "source": [
    "# Load the webcam handler\n",
    "cap = cv2.VideoCapture(0)\n",
    "time.sleep(1) ### letting the camera autofocus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection loop\n",
    "The detection loop consists of four phases:\n",
    "\n",
    "- loading the webcam frame\n",
    "\n",
    "- pre-processing the image\n",
    "\n",
    "- running the image through the network\n",
    "\n",
    "- updating the output with the resulting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "Pi93nyPjWg43",
    "outputId": "c48d922a-292e-4c39-d678-adc5015fb1dc"
   },
   "outputs": [],
   "source": [
    "axes = None\n",
    "NUM_FRAMES = 200 # you can change this\n",
    "for i in range(NUM_FRAMES):\n",
    "    # Load frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Image pre-processing\n",
    "    frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n",
    "    rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)\n",
    "\n",
    "    # Run frame through network\n",
    "    class_IDs, scores, bounding_boxes = net(rgb_nd)\n",
    "\n",
    "    # Display the result\n",
    "    img = gcv.utils.viz.cv_plot_bbox(frame, bounding_boxes[0], scores[0], class_IDs[0], class_names=net.classes)\n",
    "    gcv.utils.viz.cv_plot_image(img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUxcvGkwWg43"
   },
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv_lvY5uidpy"
   },
   "source": [
    "## Web cam Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iwBFg2e0Wg44"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "## Camera Capture\n",
    "Using a webcam to capture images for processing on the runtime.\n",
    "Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n",
    "'''\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      // show the video in the HTML element\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // prints the logs to cell\n",
    "      let jsLog = function(abc) {\n",
    "        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n",
    "      }\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      // await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      for (let i = 0; i < 5; i++) {\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        img = canvas.toDataURL('image/jpeg', quality);\n",
    "\n",
    "        // show each captured image\n",
    "        // let imgTag = document.createElement('img');\n",
    "        // imgTag.src = img;\n",
    "        // div.appendChild(imgTag);\n",
    "\n",
    "        jsLog(i + \"sending\")\n",
    "        // Call a python function and send this image\n",
    "        google.colab.kernel.invokeFunction('notebook.run_algo', [img], {});\n",
    "        jsLog(i + \"SENT\")\n",
    "        // wait for X miliseconds second, before next capture\n",
    "        await new Promise(resolve => setTimeout(resolve, 250));\n",
    "      }\n",
    "\n",
    "      stream.getVideoTracks()[0].stop(); // stop video stream\n",
    "    }\n",
    "    ''')\n",
    "  display(js) # make the provided HTML, part of the cell\n",
    "  data = eval_js('takePhoto({})'.format(quality)) # call the takePhoto() JavaScript function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SVaSNkSkiiB9",
    "outputId": "d04a4a95-92d9-4476-e91d-0ab6007c797d"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from google.colab import output\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import logging\n",
    "\n",
    "def data_uri_to_img(uri):\n",
    "    \"\"\"convert base64image to numpy array\"\"\"\n",
    "    try:\n",
    "        image = base64.b64decode(uri.split(',')[1], validate=True)\n",
    "        # make the binary image, a PIL image\n",
    "        image = Image.open(BytesIO(image))\n",
    "        # convert to numpy array\n",
    "        image = np.array(image, dtype=np.uint8);\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        logging.exception(e);\n",
    "        print('\\n')\n",
    "        return None\n",
    "\n",
    "\n",
    "def run_algo(imgB64):\n",
    "    \"\"\"\n",
    "    in Colab, run_algo function gets invoked by the JavaScript, that sends N images every second\n",
    "  \n",
    "    params:\n",
    "      image: image\n",
    "    \"\"\"\n",
    "    image = data_uri_to_img(imgB64)\n",
    "    frame = image\n",
    "    if image is None:\n",
    "        print(\"At run_algo(): image is None.\")\n",
    "        return\n",
    "    try:\n",
    "        # Run detection\n",
    "\n",
    "        # Image pre-processing\n",
    "        frame = mx.nd.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)).astype('uint8')\n",
    "        rgb_nd, frame = gcv.data.transforms.presets.ssd.transform_test(frame, short=512, max_size=700)\n",
    "\n",
    "        # Run frame through network\n",
    "        class_IDs, scores, bounding_boxes = net(rgb_nd)\n",
    "\n",
    "        # Display the result\n",
    "        img = gcv.utils.viz.cv_plot_bbox(frame, bounding_boxes[0], scores[0], class_IDs[0], class_names=net.classes)\n",
    "        #gcv.utils.viz.cv_plot_image(img)\n",
    "        #cv2.waitKey(1)\n",
    "        cv2_imshow(frame)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "\n",
    "# register this function, so JS code could call this\n",
    "output.register_callback('notebook.run_algo', run_algo)\n",
    "\n",
    "# put the JS code in cell and run it\n",
    "take_photo()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "YOLO_webcam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}