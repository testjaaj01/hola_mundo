{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33aef95c",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CV_with_Pillow.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CV_with_Pillow.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7828b",
   "metadata": {},
   "source": [
    "1. [Pillow: Basics](#Pillow-Basics)\n",
    "2. [Image Object in Pillow](#Image-Object-in-Pillow)\n",
    "3. [Displaying Images in Python with Pillow and Matplotlib](#Displaying-Images-in-Python-with-Pillow-and-Matplotlib)\n",
    "4. [Converting an Image to Grayscale and Understanding RGB Images](#Converting-an-Image-to-Grayscale-and-Understanding-RGB-Images)\n",
    "5. [Basic Image Manipulation with Pillow](#Basic-Image-Manipulation-with-Pillow)\n",
    "6. [Image Transformations: Enhancing Contrast, Brightness, Color, and Sharpness with PIL](#Image-Transformations:-Enhancing-Contrast,-Brightness,-Color,-and-Sharpness-with-PIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d4da9",
   "metadata": {},
   "source": [
    "# Pillow: Basics\n",
    "[Pillow](https://pillow.readthedocs.io/en/stable/) is an open-source Python Imaging Library that adds image processing capabilities to your Python interpreter.\n",
    "\n",
    "**Installing Pillow:**\n",
    "```python\n",
    "!pip install Pillow\n",
    "```\n",
    "\n",
    "**Key Features:**\n",
    "- Reading, writing, and manipulating images.\n",
    "- Supports a variety of file formats, including JPEG, PNG, BMP, GIF, and others.\n",
    "\n",
    "# Image Object in Pillow\n",
    "\n",
    "- Images in Pillow are represented as `Image` objects.\n",
    "- Pixel data can be accessed and modified directly.\n",
    "- Provides a range of built-in functions for image manipulation.\n",
    "\n",
    "An image in Pillow is treated as an `Image` object. To work with images, you first need to import the Pillow library and load an image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "# Download an image\n",
    "#url = 'https://upload.wikimedia.org/wikipedia/en/7/7d/Lenna_%28test_image%29.png'\n",
    "#urllib.request.urlretrieve(url, \"sample.png\")\n",
    "\n",
    "# Load an image\n",
    "image =Image.open(\"sample.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f10fae",
   "metadata": {},
   "source": [
    "**Attributes of an Image Object in Pillow:**\n",
    "\n",
    "When working with the Pillow library in Python, the `Image` object is central. It provides several attributes that give information about the image and allow for manipulation. Here's an overview of some key attributes:\n",
    "\n",
    "**`format`**\n",
    "- The `format` attribute indicates the format of the source file, such as JPEG, PNG, etc.\n",
    "\n",
    "**`size`**\n",
    "- The `size` attribute returns a tuple representing the width and height of the image in pixels.\n",
    "\n",
    "**`mode`**\n",
    "- The `mode` attribute defines the type and depth of a pixel in the image. Common modes are \"L\" for grayscale images, \"RGB\" for true color images, and \"CMYK\" for pre-press images.\n",
    "\n",
    "**`info`**\n",
    "- The `info` attribute is a dictionary containing various metadata about the image, such as \"dpi\", \"exif\", etc.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9af0ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('format:', image.format)  # Output might be 'JPEG', 'PNG', etc.\n",
    "print('size:', image.size)  # Output might be (width, height) like (640, 480)\n",
    "print('mode:', image.mode)  # Output might be 'RGB', 'L', etc.\n",
    "print('info:', image.info)  # Output might be a dictionary with metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599391e7",
   "metadata": {},
   "source": [
    "We can convert a Pillow Image object to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54e6d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Display the shape of the array\n",
    "print(image_array.shape)  # The shape will be in the form of (height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e09067",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array[:3,:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52058da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array back to a Pillow Image object\n",
    "new_image = Image.fromarray(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25dadc4",
   "metadata": {},
   "source": [
    "# Displaying Images in Python with Pillow and Matplotlib\n",
    "\n",
    "Visualizing images is a key part of working with image processing in Python. There are multiple ways to display images, the two common ones being using Pillow's built-in `.show()` method and using the `matplotlib` library.\n",
    "\n",
    "## Using Pillow's `.show()` Method\n",
    "\n",
    "Pillow's `.show()` method is the simplest way to display an image. This method opens the image in the default image viewer of your operating system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d24dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fab3597",
   "metadata": {},
   "source": [
    "## Using Matplotlib\n",
    "\n",
    "`matplotlib` is a powerful plotting library in Python that can also be used for displaying images. This method is especially useful in Jupyter notebooks or when you need more control over how the image is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60a9ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63da61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(image))\n",
    "plt.axis('off')  # Turn off axis numbers and labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab26896",
   "metadata": {},
   "source": [
    "# Converting an Image to Grayscale and Understanding RGB Images\n",
    "\n",
    "Converting color images to grayscale is a common operation in image processing. This section explains RGB images, how to split them into channels, plot these channels, and the concept of quantization.\n",
    "\n",
    "## What is an RGB Image?\n",
    "\n",
    "An RGB image is a color image composed of three color channels: Red, Green, and Blue. Each pixel in an RGB image has three values corresponding to the intensity of red, green, and blue at that pixel. These intensities usually range from 0 to 255 (8-bit quantization).\n",
    "\n",
    "## Splitting an Image into RGB Channels\n",
    "\n",
    "You can split an RGB image into its individual red, green, and blue components using Pillow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a694cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.mode)  # Output: 'RGB'\n",
    "r, g, b = image.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad52ffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "axes[0].imshow(r, cmap='Reds')\n",
    "axes[0].set_title('Red Channel')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(g, cmap='Greens')\n",
    "axes[1].set_title('Green Channel')\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(b, cmap='Blues')\n",
    "axes[2].set_title('Blue Channel')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca17bc3",
   "metadata": {},
   "source": [
    "### Converting to Grayscale\n",
    "\n",
    "Grayscale images contain only shades of gray and no color. The grayscale value is typically calculated as a weighted sum of the RGB components.\n",
    "\n",
    "When you convert an RGB image to grayscale using Pillow's convert('L') method, the mode changes from 'RGB' to 'L'. In 'L' mode, each pixel is represented by a single value, indicating luminance (or light intensity), which ranges from 0 (black) to 255 (white). This mode is used for grayscale images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad37611",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = image.convert('L')\n",
    "print(gray_image.mode)  # Output: 'L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b117126",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbeb49a",
   "metadata": {},
   "source": [
    "# Basic Image Manipulation with Pillow\n",
    "\n",
    "Pillow provides a variety of methods for basic image manipulation. These include transposing (flipping and rotating) the image, cropping, and resizing. Understanding these operations is essential for image processing tasks.\n",
    "\n",
    "## Transposing an Image\n",
    "\n",
    "The `.transpose()` method in Pillow is used to flip or rotate an image in various ways. Here are some common transpositions:\n",
    "\n",
    "- `Image.FLIP_LEFT_RIGHT`: Flip the image horizontally (left to right).\n",
    "- `Image.FLIP_TOP_BOTTOM`: Flip the image vertically (top to bottom).\n",
    "- `Image.ROTATE_90`: Rotate the image by 90 degrees.\n",
    "- `Image.ROTATE_180`: Rotate the image by 180 degrees.\n",
    "- `Image.ROTATE_270`: Rotate the image by 270 degrees.\n",
    "- `Image.TRANSPOSE`: Transpose the image (flip over the main diagonal).\n",
    "- `Image.TRANSVERSE`: Transverse the image (flip over the secondary diagonal).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcfc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different transpositions and rotations\n",
    "flipped_lr = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "flipped_tb = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "rotated_90 = image.transpose(Image.ROTATE_90)\n",
    "rotated_180 = image.transpose(Image.ROTATE_180)\n",
    "rotated_270 = image.transpose(Image.ROTATE_270)\n",
    "transposed = image.transpose(Image.TRANSPOSE)\n",
    "transversed = image.transpose(Image.TRANSVERSE)\n",
    "\n",
    "# Plotting all the images with titles\n",
    "fig, axs = plt.subplots(3, 3, figsize=(12, 12))\n",
    "\n",
    "# Original Image\n",
    "axs[0, 0].imshow(image)\n",
    "axs[0, 0].set_title(\"Original\")\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "# Flipped Left-Right\n",
    "axs[0, 1].imshow(flipped_lr)\n",
    "axs[0, 1].set_title(\"Flip Left-Right\")\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "# Flipped Top-Bottom\n",
    "axs[0, 2].imshow(flipped_tb)\n",
    "axs[0, 2].set_title(\"Flip Top-Bottom\")\n",
    "axs[0, 2].axis('off')\n",
    "\n",
    "# Rotated 90°\n",
    "axs[1, 0].imshow(rotated_90)\n",
    "axs[1, 0].set_title(\"Rotate 90°\")\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "# Rotated 180°\n",
    "axs[1, 1].imshow(rotated_180)\n",
    "axs[1, 1].set_title(\"Rotate 180°\")\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "# Rotated 270°\n",
    "axs[1, 2].imshow(rotated_270)\n",
    "axs[1, 2].set_title(\"Rotate 270°\")\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "# Transpose\n",
    "axs[2, 0].imshow(transposed)\n",
    "axs[2, 0].set_title(\"Transpose\")\n",
    "axs[2, 0].axis('off')\n",
    "\n",
    "# Transverse\n",
    "axs[2, 1].imshow(transversed)\n",
    "axs[2, 1].set_title(\"Transverse\")\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "# Empty subplot (for layout purposes)\n",
    "axs[2, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620c007",
   "metadata": {},
   "source": [
    "## Rotating an Image\n",
    "\n",
    "The `.rotate()` method allows for rotating the image by a specified number of degrees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ec54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_image = image.rotate(45)\n",
    "plt.imshow(rotated_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48eef9c5",
   "metadata": {},
   "source": [
    "## Cropping an Image\n",
    "\n",
    "\n",
    "The `crop` method in Pillow is used to cut out a rectangular portion of an image. The method takes a single argument, which is a tuple defining the left, upper, right, and lower pixel coordinate.\n",
    "\n",
    "The tuple `(left, upper, right, lower)` represents:\n",
    "\n",
    "- `left`: The x-coordinate of the leftmost edge of the cropping box.\n",
    "- `upper`: The y-coordinate of the top edge of the cropping box.\n",
    "- `right`: The x-coordinate of the rightmost edge of the cropping box.\n",
    "- `lower`: The y-coordinate of the bottom edge of the cropping box.\n",
    "\n",
    "These coordinates are relative to the top-left corner of the image, which is considered the origin `(0, 0)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b6ceaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "\n",
    "crop_box = (100, 100, 300, 300)\n",
    "\n",
    "# Create a Rectangle patch\n",
    "rect = patches.Rectangle((crop_box[0], crop_box[1]), crop_box[2] - crop_box[0], crop_box[3] - crop_box[1], linewidth=2, edgecolor='r', facecolor='none')\n",
    "\n",
    "# Plot the original image and the rectangle\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(image)\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the box to crop\n",
    "cropped_image = image.crop(crop_box)\n",
    "\n",
    "# Display the cropped image\n",
    "plt.imshow(cropped_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.size, cropped_image.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008dcac1",
   "metadata": {},
   "source": [
    "## Resizing an Image\n",
    "\n",
    "The `resize` method in Pillow is used to change the size of an image. It takes two main arguments:\n",
    "\n",
    "1. `size`: A tuple `(width, height)` representing the new size of the image.\n",
    "2. `resample`: The resampling filter to use. This is optional and determines the quality and method of the resizing. Common filters include:\n",
    "   - `Image.NEAREST`: Fastest resizing filter but with lower quality.\n",
    "   - `Image.BILINEAR`: Bilinear interpolation.\n",
    "   - `Image.BICUBIC`: Bicubic interpolation.\n",
    "   - `Image.LANCZOS`: High-quality downsampling filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_image = image.resize((200, 200), Image.LANCZOS)\n",
    "print(image.size, resized_image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def035dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizing with different methods\n",
    "nearest = image.resize((200, 200), Image.NEAREST)\n",
    "bilinear = image.resize((200, 200), Image.BILINEAR)\n",
    "bicubic = image.resize((200, 200), Image.BICUBIC)\n",
    "lanczos = image.resize((200, 200), Image.LANCZOS)\n",
    "\n",
    "# Plotting the images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "axes[0].imshow(nearest)\n",
    "axes[0].set_title(\"NEAREST\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(bilinear)\n",
    "axes[1].set_title(\"BILINEAR\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(bicubic)\n",
    "axes[2].set_title(\"BICUBIC\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "axes[3].imshow(lanczos)\n",
    "axes[3].set_title(\"LANCZOS\")\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6f3823",
   "metadata": {},
   "source": [
    "## Resizing a Cropped Image to Maintain Original Size\n",
    "\n",
    "Often, after cropping an image, you may want to resize it back to its original dimensions. This can be done by resizing the cropped image using the original image's dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a928286",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_size = image.size\n",
    "\n",
    "# Crop the image\n",
    "crop_box = (100, 100, 400, 400)\n",
    "cropped_image = image.crop(crop_box)\n",
    "\n",
    "# Resize the cropped image to the original size\n",
    "resized_cropped_image = cropped_image.resize(original_size, Image.LANCZOS)\n",
    "\n",
    "plt.imshow(resized_cropped_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801cee6e",
   "metadata": {},
   "source": [
    "## Question 1: Combining Operations\n",
    "Rotate the image 45º and flip top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd834d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91eaf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49c7c75",
   "metadata": {},
   "source": [
    "## Question 2: Combining Operations\n",
    "Crop the image to a crop box of `(50, 50, 450, 450)`, resize in to a `256 x 256 x 3` using any method, image and convert it to gray scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d051360",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_2 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6f0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_1)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de2f27",
   "metadata": {},
   "source": [
    "# Image Transformations: Enhancing Contrast, Brightness, Color, and Sharpness with PIL\n",
    "\n",
    "\n",
    "The `ImageEnhance` class in PIL provides a high-level interface for modifying specific properties of an image. It allows for straightforward adjustments to an image's contrast, brightness, color balance, and sharpness, each crucial for refining the visual appeal and clarity of images in various applications.\n",
    "\n",
    "## Contrast Enhancement\n",
    "\n",
    "**What is Contrast?**\n",
    "Contrast refers to the difference in luminance or color that makes an object distinguishable from others in an image. High contrast images have a pronounced distinction between light and dark areas, while low contrast images have a more uniform brightness or color.\n",
    "\n",
    "- **Formula:** NewPixel = ((OriginalPixel - Midpoint) * Factor) + Midpoint\n",
    "- **Factor:** Values greater than 1 increase contrast; values less than 1 decrease it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance\n",
    "\n",
    "\n",
    "# Enhance contrast\n",
    "enhancer = ImageEnhance.Contrast(image)\n",
    "contrast_image = enhancer.enhance(2)  # Increase contrast\n",
    "\n",
    "plt.imshow(contrast_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e473587",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_factors = [0.5, 1.5, 2.0]\n",
    "contrast_images = [ImageEnhance.Contrast(image).enhance(factor) for factor in contrast_factors]\n",
    "\n",
    "# Plot original and contrast-enhanced images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, contrast_image in enumerate(contrast_images, start=2):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(contrast_image)\n",
    "    plt.title(f'Contrast Factor: {contrast_factors[i-2]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621fd91a",
   "metadata": {},
   "source": [
    "## Brightness Enhancement\n",
    "\n",
    "**What is Brightness?**\n",
    "Brightness is a measure of light intensity in an image. Adjusting brightness changes how light or dark an image appears.\n",
    "\n",
    "\n",
    "- **Formula:** NewPixel = OriginalPixel * Factor\n",
    "- **Factor:** Values greater than 1 brighten the image; values less than 1 darken it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer = ImageEnhance.Brightness(image)\n",
    "bright_image = enhancer.enhance(1.5)  # Brighten the image\n",
    "\n",
    "plt.imshow(bright_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff11bf-bd70-4834-8e43-f97bc04589ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bright_factors = [0.5, 1.5, 2.0]\n",
    "bright_images = [ImageEnhance.Brightness(image).enhance(factor) for factor in bright_factors]\n",
    "\n",
    "# Plot original and contrast-enhanced images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, bright_image in enumerate(bright_images, start=2):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(bright_image)\n",
    "    plt.title(f'Bright Factor: {bright_factors[i-2]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40c1db",
   "metadata": {},
   "source": [
    "## Color Balance Enhancement\n",
    "\n",
    "**What is Color Balance?**\n",
    "Color balance adjustments affect the intensity and tone of colors in an image. This can be used to correct color casts or to enhance specific color tones.\n",
    "\n",
    "- **Factor:** An enhancement factor of 0.0 gives a black and white image. A factor of 1.0 gives the original image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer = ImageEnhance.Color(image)\n",
    "color_enhanced_image = enhancer.enhance(1.2)  # Enhance color\n",
    "\n",
    "plt.imshow(color_enhanced_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5beca39-adb3-4f5a-ad3e-7e0d5eaf1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_factors = [0.25, 0.75, 1.5]\n",
    "color_images = [ImageEnhance.Color(image).enhance(factor) for factor in color_factors]\n",
    "\n",
    "# Plot original and contrast-enhanced images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, color_image in enumerate(color_images, start=2):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(color_image)\n",
    "    plt.title(f'Color Factor: {color_factors[i-2]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705131a",
   "metadata": {},
   "source": [
    "## Sharpness Enhancement\n",
    "\n",
    "**What is Sharpness?**\n",
    "Sharpness enhancement increases the clarity of detail in an image by emphasizing edges and fine details.\n",
    "\n",
    "\n",
    "- **Factor:** Values greater than 1 increase sharpness; values less than 1 decrease it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e59c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhancer = ImageEnhance.Sharpness(image)\n",
    "sharp_image = enhancer.enhance(2)  # Sharpen the image\n",
    "\n",
    "plt.imshow(sharp_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b95c0-076d-4f20-85d1-6e0e50181c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp_factors = [0.5, 1.5, 2.0]\n",
    "sharp_images = [ImageEnhance.Sharpness(image).enhance(factor) for factor in sharp_factors]\n",
    "\n",
    "# Plot original and contrast-enhanced images\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "for i, bright_image in enumerate(sharp_images, start=2):\n",
    "    plt.subplot(2, 2, i)\n",
    "    plt.imshow(sharp_image)\n",
    "    plt.title(f'Sharp Factor: {sharp_factors[i-2]}')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033ed75",
   "metadata": {},
   "source": [
    "## Interactive Demonstration with ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2174dfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def interactive_enhancements(brightness, contrast, color, sharpness):\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    enhanced_image = enhancer.enhance(brightness)\n",
    "\n",
    "    enhancer = ImageEnhance.Contrast(enhanced_image)\n",
    "    enhanced_image = enhancer.enhance(contrast)\n",
    "\n",
    "    enhancer = ImageEnhance.Color(enhanced_image)\n",
    "    enhanced_image = enhancer.enhance(color)\n",
    "\n",
    "    enhancer = ImageEnhance.Sharpness(enhanced_image)\n",
    "    enhanced_image = enhancer.enhance(sharpness)\n",
    "\n",
    "    plt.imshow(enhanced_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "brightness_slider = widgets.FloatSlider(min=0.1, max=2.0, step=0.1, value=1.0, description='Brightness:')\n",
    "contrast_slider = widgets.FloatSlider(min=0.1, max=2.0, step=0.1, value=1.0, description='Contrast:')\n",
    "color_slider = widgets.FloatSlider(min=0.1, max=2.0, step=0.1, value=1.0, description='Color:')\n",
    "sharpness_slider = widgets.FloatSlider(min=0.1, max=2.0, step=0.1, value=1.0, description='Sharpness:')\n",
    "\n",
    "widgets.interactive(interactive_enhancements, brightness=brightness_slider, contrast=contrast_slider, color=color_slider, sharpness=sharpness_slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
