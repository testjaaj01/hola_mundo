{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/CNN/cat_vs_dogs.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/cat_vs_dogs.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xMF893leGzR"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Tensorflow  Dataset\n",
    "[Tensorflow tf.data.Dataset tutorial](https://www.tensorflow.org/guide/data)\n",
    "\n",
    "TensorFlow's tf.data API, which provides a convenient way to create efficient input pipelines for training and evaluation of machine learning models. `tf.data.Dataset` is an abstraction of a\n",
    "sequence of elements.\n",
    "\n",
    "The first step to using the tf.data API is creating a Dataset object. Datasets can be created from various sources, including in-memory data, files, or by generating data on-the-fly.\n",
    "\n",
    "For this example, let's create a dataset from an in-memory NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample NumPy array\n",
    "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# Create a tf.data Dataset from the NumPy array\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` object is a Python iterable. This makes it possible to consume its\n",
    "elements using a for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in dataset:\n",
    "      print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset, we can apply various transformations to prepare the data for training. Some common transformations include shuffling, batching, and repeating.\n",
    "\n",
    "**Shuffle**\n",
    "\n",
    "Randomly shuffles the elements of this dataset.\n",
    "\n",
    "This dataset fills a buffer with buffer_size elements, then randomly samples elements from this buffer, replacing the selected elements with new elements. For perfect shuffling, a buffer size greater than or equal to the full size of the dataset is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 2\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size)\n",
    "\n",
    "for elem in dataset:\n",
    "      print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch**\n",
    "\n",
    "Combines consecutive elements of this dataset into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "for elem in dataset:\n",
    "      print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to using in-memory data, the `tf.data` API can also read data from files, such as images or text files. For example, let's create a dataset of text lines from a sample file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample text file\n",
    "with open(\"sample.txt\", \"w\") as f:\n",
    "    f.write(\"This is a sample text file.\\n\")\n",
    "    f.write(\"Each line represents an element in the dataset.\\n\")\n",
    "    f.write(\"We can apply various transformations to the data.\\n\")\n",
    "    f.write(\"This makes it easy to prepare data for training.\\n\")\n",
    "\n",
    "# Create a tf.data Dataset from the text file\n",
    "dataset = tf.data.TextLineDataset(\"sample.txt\")\n",
    "for elem in dataset:\n",
    "      print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To preprocess the text data, we can apply a map function to the dataset. This allows us to perform arbitrary operations on each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a preprocessing function\n",
    "def preprocess_text(line):\n",
    "    line = tf.strings.lower(line)\n",
    "    line = tf.strings.strip(line)\n",
    "    return line\n",
    "\n",
    "# Apply the preprocessing function to the dataset\n",
    "dataset = dataset.map(preprocess_text)\n",
    "\n",
    "for elem in dataset:\n",
    "      print(elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat vs dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpljkU2seGzT",
    "outputId": "ed2bdcf1-3910-4e67-c58b-51d097ff03e6"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True)\n",
    "dataset = dataset['train']\n",
    "class_names = ['cat', 'dog']\n",
    "\n",
    "size = tf.data.experimental.cardinality(dataset).numpy()\n",
    "print(f'number of images:{size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUfigIhzeGzU"
   },
   "source": [
    "We need all images to be the same size, we can use [`resize`](https://www.tensorflow.org/api_docs/python/tf/image/resize):\n",
    "\n",
    "```python\n",
    "tf.image.resize(\n",
    "    images, size, method=ResizeMethod.BILINEAR, preserve_aspect_ratio=False,\n",
    "    antialias=False, name=None\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-HXP86oeGzV"
   },
   "outputs": [],
   "source": [
    "image_size = (96, 96, 3)\n",
    "\n",
    "\n",
    "def preprocess_img(images, size=(96, 96)):\n",
    "    return tf.image.resize(images, size)\n",
    "\n",
    "dataset = dataset.map(lambda images, labels: (preprocess_img(images), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BsJAD-MeGzV"
   },
   "source": [
    "Split the dataset, you can use [different techniques](https://www.tensorflow.org/datasets/splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QdQBZWhweGzW"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_size = int(0.75 * size)\n",
    "val_size = int(0.1 * size)\n",
    "\n",
    "train_ds = dataset.take(train_size)\n",
    "train_ds = train_ds.shuffle(1000).batch(batch_size).cache()\n",
    "remaining = dataset.skip(train_size)\n",
    "\n",
    "val_ds = remaining.take(val_size)\n",
    "test_ds = remaining.skip(val_size)\n",
    "\n",
    "val_ds = val_ds.shuffle(1000).batch(batch_size).cache()\n",
    "test_ds = test_ds.batch(batch_size).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnCcVzx5eGzW"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "CHniUhfpeGzW",
    "outputId": "00ad9607-4a79-486e-c198-2b312415a977"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model\n",
    "\n",
    "You can visit the tutorial [Introduction_to_CNN](https://github.com/ezponda/intro_deep_learning/blob/main/class/CNN/Introduction_to_CNN.ipynb)\n",
    "\n",
    "## CNN model in Keras\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://i.ibb.co/D8CmT6K/cnn.jpg\" alt=\"cnn\" border=\"0\">\n",
    "\n",
    "\n",
    "\n",
    "A Convolutional Neural Network (CNN) architecture has four main parts:\n",
    "\n",
    "- A **convolutional layer** that extracts features from a source image. \n",
    "\n",
    "- A **pooling layer** that reduces the image dimensionality without losing important features or patterns.\n",
    "\n",
    "- A **flattening layer** that transforms a n-dimensional tensor into a vector that can be fed into a fully connected neural network.\n",
    "\n",
    "- A **fully connected layer** also known as the dense layer.\n",
    "\n",
    "### Rescaling\n",
    "\n",
    "For converting the images to   \\[0,1\\] range.\n",
    "```python\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "next_layer = normalization_layer(prev_layer)\n",
    "```\n",
    "or simply\n",
    "```python\n",
    "reescaling = layers.Rescaling(1. / 255)(inputs)\n",
    "```\n",
    "\n",
    "### Convolutional layer\n",
    "\n",
    "In the convolutional layers (`Conv2D`) we will configure the following parameters:\n",
    "\n",
    "- **filters**: number of feature maps.\n",
    "- **kernel_size**: can be either an integer or a tuple of two integers. Specifies the height and width of the kernel.\n",
    "- **padding**: allows you to include padding in the input data. With 'valid' it is not applied, with 'same' it is configured so that the dimension at the output of the convolution is the same as at the input.\n",
    "- **activation**: activation function implemented. Recommended ReLU.\n",
    "\n",
    "[Link to documentation](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Conv2D(\n",
    "    filters, kernel_size, strides=(1, 1), padding='valid',\n",
    "    activation=None, kernel_regularizer=None)\n",
    "\n",
    "```\n",
    "\n",
    "With Functional API:\n",
    "```python\n",
    "next_layer = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv_1')(prev_layer)\n",
    "```\n",
    "\n",
    "With Sequential:\n",
    "```python\n",
    "model.add(layers.Conv2D(filters=8,kernel_size=3, activation='relu', name='conv_1'))\n",
    "```\n",
    "\n",
    "### Pooling layer\n",
    "\n",
    "A pooling layer is a new layer added after the convolutional layer. Specifically, after a nonlinearity ( ReLU) you can choose between [average pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D) or [max pooling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D). Usually max pooling is the best choice.\n",
    "\n",
    "\n",
    "With Functional API:\n",
    "```python\n",
    "conv_1 = layers.Conv2D(filters=8, kernel_size=3, activation='relu', name='conv_1')(prev_layer)\n",
    "\n",
    "pool_1 = layers.MaxPool2D(pool_size=(2, 2), name='pool_1')(conv_1)\n",
    "```\n",
    "\n",
    "With Sequential:\n",
    "```python\n",
    "model.add(layers.AveragePooling2D(pool_size=(2, 2), name='pool_1'))\n",
    "```\n",
    "\n",
    "### Flattening\n",
    "\n",
    "Prepares a vector for the fully connected layers.\n",
    "\n",
    "With Functional API:\n",
    "\n",
    "```python\n",
    "next_layer = layers.Flatten(name='flatten')(prev_layer)\n",
    "```\n",
    "\n",
    "With Sequential:\n",
    "```python\n",
    "model.add(layers.Flatten(name='flatten'))\n",
    "```\n",
    "\n",
    "There is another alternative for flattening that is a type of pooling that is called global pooling. Global pooling down-samples the entire feature map to a single value. \n",
    "\n",
    "You can also choose between [GlobalAveragePooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D) and [GlobalMaxPooling2D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalMaxPool2D).\n",
    "\n",
    "```python\n",
    "model.add(layers.GlobalMaxPool2D(name='GlobalMaxPooling2D'))\n",
    "```\n",
    "\n",
    "### Fully-connected layer\n",
    "\n",
    "Dense layer like a simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "os9E78maeGzX"
   },
   "source": [
    "## Question 1: Create a model with two convolutional layers without pooling and without any regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdO4EeDWeGzX"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "reescaling = ...(inputs)\n",
    "\n",
    "# Conv Layer 1\n",
    "conv_1 = layers.Conv2D(...)(reescaling)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv_2 = ...\n",
    "\n",
    "\n",
    "# Fully-connected\n",
    "# Flattening\n",
    "flat = ...(conv_2)\n",
    "...\n",
    "outputs = layers.Dense(...)(...)\n",
    "\n",
    "model_1 = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shEsohu4eGzY"
   },
   "outputs": [],
   "source": [
    "model_1.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ZQu8L9FeGzY",
    "outputId": "ba3b3fe1-1689-4b89-a7bf-80eb674a5d70"
   },
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=2,  \n",
    "    verbose=1)\n",
    "\n",
    "history = model_1.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GdcLg1ueGzY",
    "outputId": "fe93de71-d39b-4789-f435-ebf4e508e430"
   },
   "outputs": [],
   "source": [
    "results = model_1.evaluate(test_ds, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ddszTEMXeGzZ",
    "outputId": "a54caaa2-356f-4262-f1b8-c4148de00fdd"
   },
   "outputs": [],
   "source": [
    "def show_errors(val_ds, model, class_names, n_images=10):\n",
    "    n_plots = 0\n",
    "    for images, labels in val_ds:\n",
    "        pred_prob = model.predict(images)\n",
    "        preds = (1.0 * (pred_prob >= 0.5)).astype(np.int32).flatten()\n",
    "        bad_pred_inds = np.where(preds != labels)[0]\n",
    "        for ind in list(bad_pred_inds):\n",
    "            n_plots += 1\n",
    "            real_class = class_names[labels[ind].numpy()]\n",
    "            pred_class = class_names[preds[ind]]\n",
    "            prob = pred_prob[ind][0]\n",
    "            plt.imshow(images[ind].numpy().astype(\"uint8\"))\n",
    "            plt.title('Predicted: {0}, prob: {1:.2f} \\n real: {2}'.format(\n",
    "                pred_class, prob, real_class))\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            if n_plots == n_images:\n",
    "                return\n",
    "    return\n",
    "\n",
    "\n",
    "show_errors(test_ds, model_1, class_names, n_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1U9Rb52meGzZ"
   },
   "source": [
    "## Question 2: Introduce pooling to the previous model and obtain a better `test_accuracy`, Do not use any regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFB6mSPleGzZ"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "reescaling = ...(inputs)\n",
    "\n",
    "# Conv Layer 1 + pooling\n",
    "conv_1 = layers.Conv2D(...)(reescaling)\n",
    "\n",
    "# Conv Layer 2 + pooling\n",
    "conv_2 = ...\n",
    "\n",
    "\n",
    "# Fully-connected\n",
    "# Flattening\n",
    "flat = ...(conv_2)\n",
    "...\n",
    "outputs = layers.Dense(...)(...)\n",
    "\n",
    "model_2 = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHmyPzpSeGza",
    "outputId": "55b3e725-c4ee-4138-9c05-2e50784fd9fb"
   },
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=2,  \n",
    "    verbose=1)\n",
    "\n",
    "history = model_2.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-cPzXS2eGzb",
    "outputId": "9b34986a-1091-43ed-f4b2-e3c1d2174d29"
   },
   "outputs": [],
   "source": [
    "results = model_2.evaluate(test_ds, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mbWhsrsbeGzb",
    "outputId": "78b2bb44-b314-4038-df9e-df79af17776b"
   },
   "outputs": [],
   "source": [
    "show_errors(test_ds, model_2, class_names, n_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7s_yNBoeGzb"
   },
   "source": [
    "## Question 3: Introduce regularization (you can try data augmentation) and increase the number of layers to obtain a better `test_accuracy`. Try to obtain `Test Accuracy > 0.82`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7crf8IheGzb"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(),\n",
    "    layers.RandomRotation(0.25),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-RS8OYieGzc"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=..., name='input')\n",
    "reescaling = ...(inputs)\n",
    "\n",
    "# Conv Layer 1\n",
    "conv_1 = layers.Conv2D(...)(reescaling)\n",
    "\n",
    "# Conv Layer 2\n",
    "conv_2 = ...\n",
    "\n",
    "# Conv Layer ...\n",
    "\n",
    "\n",
    "# Fully-connected\n",
    "# Flattening\n",
    "flat = ...\n",
    "...\n",
    "outputs = layers.Dense(...)(...)\n",
    "\n",
    "model_3 = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oEUl7FLmeGzc",
    "outputId": "6fe26b09-6ac4-4e2f-9d6e-05d92de86aff"
   },
   "outputs": [],
   "source": [
    "model_3.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 8\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=2,  \n",
    "    verbose=1)\n",
    "\n",
    "history = model_3.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVRhbjwceGzc",
    "outputId": "7ecfc0a9-7d60-4ef9-adc6-8c0987bd9a98"
   },
   "outputs": [],
   "source": [
    "results = model_3.evaluate(test_ds, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BqVSj6xieGzd",
    "outputId": "020933e3-a8a0-4351-b290-bc89e8dfb653"
   },
   "outputs": [],
   "source": [
    "show_errors(test_ds, model_3, class_names, n_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1 (Optional): Tune a CNN Architecture with Keras Tuner\n",
    "\n",
    "[Keras Tuner tutorial](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb) :\n",
    "\n",
    "Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
    "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
    "\n",
    "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
    "\n",
    "```python\n",
    "def build_model(hp):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "```\n",
    "\n",
    "- `hp.Int` to sample an integer from a certain range:\n",
    "```python\n",
    "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
    "```\n",
    "- `hp.Float` to sample a float number from a certain range:\n",
    "```python\n",
    "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
    "```\n",
    "- `hp.Choice` to select values in a list:\n",
    "```python\n",
    "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "```\n",
    "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(hp):\n",
    "    \"\"\"Build a CNN model with tunable architecture and dropout regularization using Functional API.\"\"\"\n",
    "    inputs = keras.Input(shape=image_size)\n",
    "    \n",
    "    # Start the model flow with the inputs\n",
    "    x = layers.Rescaling(1. / 255)(inputs)\n",
    "\n",
    "    # Tune the number of convolutional blocks (try 1-3 blocks)\n",
    "    for i in range(hp.Int('num_conv_blocks', min_value=1, max_value=3)):\n",
    "        # Tune the number of filters in each Conv2D layer\n",
    "        x = layers.Conv2D(\n",
    "            filters=hp.Int(f'filters_{i}', min_value=16, max_value=128, step=16),\n",
    "            kernel_size=hp.Choice(f'kernel_size_{i}', values=[3, 5]),\n",
    "            activation='relu',\n",
    "            padding='same'\n",
    "        )(x)\n",
    "        \n",
    "        # Add dropout after the Conv2D layer\n",
    "        x = layers.Dropout(\n",
    "            hp.Float(f'conv_dropout_{i}', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        )(x)\n",
    "        \n",
    "        # Add pooling layer\n",
    "        x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # Flatten layer before dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    x = layers.Dense(\n",
    "        units=hp.Int('dense_units', min_value=32, max_value=128, step=32),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.Dropout(\n",
    "        hp.Float('dense_dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    )(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(build_cnn_model,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=2,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "# Early stopping callback\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Start the search\n",
    "tuner.search(\n",
    "    train_ds,  # Use your TensorFlow dataset\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=[es_callback]\n",
    ")\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the optimal architecture\n",
    "print(f\"Best number of convolutional blocks: {best_hps.get('num_conv_blocks')}\")\n",
    "for i in range(best_hps.get('num_conv_blocks')):\n",
    "    print(f\"Conv block {i+1}:\")\n",
    "    print(f\"  - Filters: {best_hps.get(f'filters_{i}')}\")\n",
    "    print(f\"  - Kernel size: {best_hps.get(f'kernel_size_{i}')}\")\n",
    "    print(f\"  - Dropout rate: {best_hps.get(f'conv_dropout_{i}')}\")\n",
    "\n",
    "print(f\"Dense layer units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Dense layer dropout: {best_hps.get('dense_dropout')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model with the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "history = best_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=25,\n",
    "    callbacks=[es_callback]\n",
    ")\n",
    "\n",
    "# Evaluate on test dataset\n",
    "test_loss, test_accuracy = best_model.evaluate(test_ds)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fVV15W3eGzd"
   },
   "source": [
    "## Question 4: Try transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3IQloZXeGzd",
    "outputId": "ad4cd66b-1e94-4c8f-da73-ca890e13f6aa"
   },
   "outputs": [],
   "source": [
    "pretrained_model = tf.keras.applications.MobileNetV2(input_shape=image_size,\n",
    "                                                     include_top=False)\n",
    "pretrained_model.trainable = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCLm_hBGeGzd"
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rjxajIYceGzd",
    "outputId": "1269322b-9171-41b7-a70e-3d583d26762b"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=image_size, name='input')\n",
    "\n",
    "# pre-trained model\n",
    "... = preprocess_input(...)\n",
    "... = pretrained_model(..)\n",
    "\n",
    "# classifier\n",
    "flat = tf.keras.layers.Flatten()(...)\n",
    "outputs = ...\n",
    "\n",
    "model_tl = tf.keras.Model(inputs, outputs)\n",
    "model_tl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IKakf7heGze",
    "outputId": "2eea5456-ab51-4acb-be87-bf6c2a570965"
   },
   "outputs": [],
   "source": [
    "model_tl.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=2,  \n",
    "    verbose=1)\n",
    "\n",
    "history = model_tl.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rj6g177WeGze",
    "outputId": "270d8265-3d0a-4b95-dd7e-584eb6ca464e"
   },
   "outputs": [],
   "source": [
    "results = model_tl.evaluate(test_ds, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))\n",
    "print('Test Accuracy: {}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xJvi9oS9eGze",
    "outputId": "3f3a244c-5c79-47fa-bb7d-9436556daf2f"
   },
   "outputs": [],
   "source": [
    "show_errors(test_ds, model_tl, class_names, n_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61S2aJJYeGzf"
   },
   "source": [
    "# Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q2SOYs-9eGzf"
   },
   "outputs": [],
   "source": [
    "def read_image(image_path, target_size=None):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path,\n",
    "                target_size=target_size)\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "def predict_plot(image_path, model, class_names, image_size):\n",
    "    image = read_image(image_path, image_size[:2])\n",
    "    prob = model.predict(np.expand_dims(image, 0))[0][0]\n",
    "    pred_class = class_names[(1.0 * (prob >= 0.5)).astype(np.int32)]\n",
    "    plt.imshow(image)\n",
    "    plt.title(\n",
    "        'Predicted: {0}, prob: {1:.2f}'\n",
    "        .format(pred_class, prob))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YmKbvB5BeGzf",
    "outputId": "02e14bb0-2c47-4510-ce8e-e898f190c47d"
   },
   "outputs": [],
   "source": [
    "url = 'https://assets.sainsburys-groceries.co.uk/gol/6754229/1/640x640.jpg'\n",
    "image_path = tf.keras.utils.get_file(\"dog_vs_cat_1.jpg\", url)\n",
    "print('model 1')\n",
    "predict_plot(image_path, model_1, class_names, image_size)\n",
    "print('model 2')\n",
    "predict_plot(image_path, model_2, class_names, image_size)\n",
    "print('model 3')\n",
    "predict_plot(image_path, model_3, class_names, image_size)\n",
    "print('model tl')\n",
    "predict_plot(image_path, model_tl, class_names, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "B4G4AWB0eGzf",
    "outputId": "aedb1323-3af3-475b-ab65-4441648cda12"
   },
   "outputs": [],
   "source": [
    "url = 'https://i.ytimg.com/vi/3dcli9i_pvA/hqdefault.jpg'\n",
    "image_path = tf.keras.utils.get_file(\"dog_vs_cat_2.jpg\", url)\n",
    "print('model 1')\n",
    "predict_plot(image_path, model_1, class_names, image_size)\n",
    "print('model 2')\n",
    "predict_plot(image_path, model_2, class_names, image_size)\n",
    "print('model 3')\n",
    "predict_plot(image_path, model_3, class_names, image_size)\n",
    "print('model tl')\n",
    "predict_plot(image_path, model_tl, class_names, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fijCROyseGzg",
    "outputId": "cf50d04b-3f33-4797-cae7-5a734a84283c"
   },
   "outputs": [],
   "source": [
    "url = 'https://thumbs.dreamstime.com/b/halloween-ghost-portrait-funny-dog-black-background-adorable-pup-muzle-153863580.jpg'\n",
    "image_path = tf.keras.utils.get_file(\"dog_vs_cat_3.jpg\", url)\n",
    "print('model 1')\n",
    "predict_plot(image_path, model_1, class_names, image_size)\n",
    "print('model 2')\n",
    "predict_plot(image_path, model_2, class_names, image_size)\n",
    "print('model 3')\n",
    "predict_plot(image_path, model_3, class_names, image_size)\n",
    "print('model tl')\n",
    "predict_plot(image_path, model_tl, class_names, image_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cat_vs_dogs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
